{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thyarles/unb-fmc-nlp/blob/main/aula_1/bpe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV1x2AARpgTB"
      },
      "source": [
        "# Atividade: Aplicação do Algoritmo BPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iWHmcK2UX6K",
        "outputId": "02dbc95d-6b30-4121-d4f1-28a3d69b899e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arquivo corpus lido com 20000 linhas!\n"
          ]
        }
      ],
      "source": [
        "# Vamos baixar o corpus previamente preparado e descompactar\n",
        "import os\n",
        "\n",
        "file_path = './corpus.txt'\n",
        "corpus = ''\n",
        "lines = 0\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "      corpus = file.read()\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "      lines = sum(1 for line in file)\n",
        "    print(f'Arquivo corpus lido com {lines} linhas!')\n",
        "else:\n",
        "    url = 'https://raw.githubusercontent.com/thyarles/unb-fmc-nlp/refs/heads/main/aula_1/corpus.tar.xz'\n",
        "    cmd = ! wget {url} && tar -xvJf corpus.tar.xz && echo \"Ok, arquivo corpus recuperado! Rode a célula novamente.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ty1YCjtzpnE9"
      },
      "outputs": [],
      "source": [
        "# Vamos baixar os arquivos necessários com a biblioteca request\n",
        "\n",
        "# Se estiver usando Google Colab, habilite o by_request\n",
        "by_request = False\n",
        "\n",
        "if by_request:\n",
        "    # Vamos baixar o módulo bpe.py\n",
        "    url = \"https://raw.githubusercontent.com/thyarles/unb-fmc-nlp/refs/heads/main/aula_1/bpe.py\"\n",
        "    cmd = ! wget {url}\n",
        "\n",
        "    # Vamos baixar o pickles se existir\n",
        "    url = 'https://raw.githubusercontent.com/thyarles/unb-fmc-nlp/refs/heads/main/aula_1/my_bpe.pkl'\n",
        "    cmd = ! wget {url}\n",
        "else:\n",
        "    from bpe import MyBPE\n",
        "\n",
        "# Vamos instanciar o modelo\n",
        "my_bpe = MyBPE()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "FiVnteCuqNPw",
        "outputId": "3df114d6-d4c9-4a5e-bb48-835c39a5922c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo será treinado.\n",
            "Merge 0 de 244...\n",
            "Merge 1 de 244...\n",
            "Merge 2 de 244...\n",
            "Merge 3 de 244...\n",
            "Merge 4 de 244...\n",
            "Merge 5 de 244...\n",
            "Merge 6 de 244...\n",
            "Merge 7 de 244...\n",
            "Merge 8 de 244...\n",
            "Merge 9 de 244...\n",
            "Merge 10 de 244...\n",
            "Merge 11 de 244...\n",
            "Merge 12 de 244...\n",
            "Merge 13 de 244...\n",
            "Merge 14 de 244...\n",
            "Merge 15 de 244...\n",
            "Merge 16 de 244...\n",
            "Merge 17 de 244...\n",
            "Merge 18 de 244...\n",
            "Merge 19 de 244...\n",
            "Merge 20 de 244...\n",
            "Merge 21 de 244...\n",
            "Merge 22 de 244...\n",
            "Merge 23 de 244...\n",
            "Merge 24 de 244...\n",
            "Merge 25 de 244...\n",
            "Merge 26 de 244...\n",
            "Merge 27 de 244...\n",
            "Merge 28 de 244...\n",
            "Merge 29 de 244...\n",
            "Merge 30 de 244...\n",
            "Merge 31 de 244...\n",
            "Merge 32 de 244...\n",
            "Merge 33 de 244...\n",
            "Merge 34 de 244...\n",
            "Merge 35 de 244...\n",
            "Merge 36 de 244...\n",
            "Merge 37 de 244...\n",
            "Merge 38 de 244...\n",
            "Merge 39 de 244...\n",
            "Merge 40 de 244...\n",
            "Merge 41 de 244...\n",
            "Merge 42 de 244...\n",
            "Merge 43 de 244...\n",
            "Merge 44 de 244...\n",
            "Merge 45 de 244...\n",
            "Merge 46 de 244...\n",
            "Merge 47 de 244...\n",
            "Merge 48 de 244...\n",
            "Merge 49 de 244...\n",
            "Merge 50 de 244...\n",
            "Merge 51 de 244...\n",
            "Merge 52 de 244...\n",
            "Merge 53 de 244...\n",
            "Merge 54 de 244...\n",
            "Merge 55 de 244...\n",
            "Merge 56 de 244...\n",
            "Merge 57 de 244...\n",
            "Merge 58 de 244...\n",
            "Merge 59 de 244...\n",
            "Merge 60 de 244...\n",
            "Merge 61 de 244...\n",
            "Merge 62 de 244...\n",
            "Merge 63 de 244...\n",
            "Merge 64 de 244...\n",
            "Merge 65 de 244...\n",
            "Merge 66 de 244...\n",
            "Merge 67 de 244...\n",
            "Merge 68 de 244...\n",
            "Merge 69 de 244...\n",
            "Merge 70 de 244...\n",
            "Merge 71 de 244...\n",
            "Merge 72 de 244...\n",
            "Merge 73 de 244...\n",
            "Merge 74 de 244...\n",
            "Merge 75 de 244...\n",
            "Merge 76 de 244...\n",
            "Merge 77 de 244...\n",
            "Merge 78 de 244...\n",
            "Merge 79 de 244...\n",
            "Merge 80 de 244...\n",
            "Merge 81 de 244...\n",
            "Merge 82 de 244...\n",
            "Merge 83 de 244...\n",
            "Merge 84 de 244...\n",
            "Merge 85 de 244...\n",
            "Merge 86 de 244...\n",
            "Merge 87 de 244...\n",
            "Merge 88 de 244...\n",
            "Merge 89 de 244...\n",
            "Merge 90 de 244...\n",
            "Merge 91 de 244...\n",
            "Merge 92 de 244...\n",
            "Merge 93 de 244...\n",
            "Merge 94 de 244...\n",
            "Merge 95 de 244...\n",
            "Merge 96 de 244...\n",
            "Merge 97 de 244...\n",
            "Merge 98 de 244...\n",
            "Merge 99 de 244...\n",
            "Merge 100 de 244...\n",
            "Merge 101 de 244...\n",
            "Merge 102 de 244...\n",
            "Merge 103 de 244...\n",
            "Merge 104 de 244...\n",
            "Merge 105 de 244...\n",
            "Merge 106 de 244...\n",
            "Merge 107 de 244...\n",
            "Merge 108 de 244...\n",
            "Merge 109 de 244...\n",
            "Merge 110 de 244...\n",
            "Merge 111 de 244...\n",
            "Merge 112 de 244...\n",
            "Merge 113 de 244...\n",
            "Merge 114 de 244...\n",
            "Merge 115 de 244...\n",
            "Merge 116 de 244...\n",
            "Merge 117 de 244...\n",
            "Merge 118 de 244...\n",
            "Merge 119 de 244...\n",
            "Merge 120 de 244...\n",
            "Merge 121 de 244...\n",
            "Merge 122 de 244...\n",
            "Merge 123 de 244...\n",
            "Merge 124 de 244...\n",
            "Merge 125 de 244...\n",
            "Merge 126 de 244...\n",
            "Merge 127 de 244...\n",
            "Merge 128 de 244...\n",
            "Merge 129 de 244...\n",
            "Merge 130 de 244...\n",
            "Merge 131 de 244...\n",
            "Merge 132 de 244...\n",
            "Merge 133 de 244...\n",
            "Merge 134 de 244...\n",
            "Merge 135 de 244...\n",
            "Merge 136 de 244...\n",
            "Merge 137 de 244...\n",
            "Merge 138 de 244...\n",
            "Merge 139 de 244...\n",
            "Merge 140 de 244...\n",
            "Merge 141 de 244...\n",
            "Merge 142 de 244...\n",
            "Merge 143 de 244...\n",
            "Merge 144 de 244...\n",
            "Merge 145 de 244...\n",
            "Merge 146 de 244...\n",
            "Merge 147 de 244...\n",
            "Merge 148 de 244...\n",
            "Merge 149 de 244...\n",
            "Merge 150 de 244...\n",
            "Merge 151 de 244...\n",
            "Merge 152 de 244...\n",
            "Merge 153 de 244...\n",
            "Merge 154 de 244...\n",
            "Merge 155 de 244...\n",
            "Merge 156 de 244...\n",
            "Merge 157 de 244...\n",
            "Merge 158 de 244...\n",
            "Merge 159 de 244...\n",
            "Merge 160 de 244...\n",
            "Merge 161 de 244...\n",
            "Merge 162 de 244...\n",
            "Merge 163 de 244...\n",
            "Merge 164 de 244...\n",
            "Merge 165 de 244...\n",
            "Merge 166 de 244...\n",
            "Merge 167 de 244...\n",
            "Merge 168 de 244...\n",
            "Merge 169 de 244...\n",
            "Merge 170 de 244...\n",
            "Merge 171 de 244...\n",
            "Merge 172 de 244...\n",
            "Merge 173 de 244...\n",
            "Merge 174 de 244...\n",
            "Merge 175 de 244...\n",
            "Merge 176 de 244...\n",
            "Merge 177 de 244...\n",
            "Merge 178 de 244...\n",
            "Merge 179 de 244...\n",
            "Merge 180 de 244...\n",
            "Merge 181 de 244...\n",
            "Merge 182 de 244...\n",
            "Merge 183 de 244...\n",
            "Merge 184 de 244...\n",
            "Merge 185 de 244...\n",
            "Merge 186 de 244...\n",
            "Merge 187 de 244...\n",
            "Merge 188 de 244...\n",
            "Merge 189 de 244...\n",
            "Merge 190 de 244...\n",
            "Merge 191 de 244...\n",
            "Merge 192 de 244...\n",
            "Merge 193 de 244...\n",
            "Merge 194 de 244...\n",
            "Merge 195 de 244...\n",
            "Merge 196 de 244...\n",
            "Merge 197 de 244...\n",
            "Merge 198 de 244...\n",
            "Merge 199 de 244...\n",
            "Merge 200 de 244...\n",
            "Merge 201 de 244...\n",
            "Merge 202 de 244...\n",
            "Merge 203 de 244...\n",
            "Merge 204 de 244...\n",
            "Merge 205 de 244...\n",
            "Merge 206 de 244...\n",
            "Merge 207 de 244...\n",
            "Merge 208 de 244...\n",
            "Merge 209 de 244...\n",
            "Merge 210 de 244...\n",
            "Merge 211 de 244...\n",
            "Merge 212 de 244...\n",
            "Merge 213 de 244...\n",
            "Merge 214 de 244...\n",
            "Merge 215 de 244...\n",
            "Merge 216 de 244...\n",
            "Merge 217 de 244...\n",
            "Merge 218 de 244...\n",
            "Merge 219 de 244...\n",
            "Merge 220 de 244...\n",
            "Merge 221 de 244...\n",
            "Merge 222 de 244...\n",
            "Merge 223 de 244...\n",
            "Merge 224 de 244...\n",
            "Merge 225 de 244...\n",
            "Merge 226 de 244...\n",
            "Merge 227 de 244...\n",
            "Merge 228 de 244...\n",
            "Merge 229 de 244...\n",
            "Merge 230 de 244...\n",
            "Merge 231 de 244...\n",
            "Merge 232 de 244...\n",
            "Merge 233 de 244...\n",
            "Merge 234 de 244...\n",
            "Merge 235 de 244...\n",
            "Merge 236 de 244...\n",
            "Merge 237 de 244...\n",
            "Merge 238 de 244...\n",
            "Merge 239 de 244...\n",
            "Merge 240 de 244...\n",
            "Merge 241 de 244...\n",
            "Merge 242 de 244...\n",
            "Merge 243 de 244...\n",
            "Treinamento em 4063.78 segundos.\n",
            "Modelo salvo em 'my_bpe.pkl'.\n"
          ]
        }
      ],
      "source": [
        "# Vamos treinar\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Modelo\n",
        "model_file = 'my_bpe.pkl'\n",
        "\n",
        "if os.path.exists(model_file):\n",
        "    # Se tiver modelo treinado, leia\n",
        "    print(\"Modelo será lido de 'my_bpe.pkl'.\")\n",
        "    with open(model_file, 'rb') as file:\n",
        "        my_bpe = pickle.load(file)\n",
        "else:\n",
        "    # Se não, treine\n",
        "    print(\"Modelo será treinado.\")\n",
        "\n",
        "    # Inicio\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Treina\n",
        "    my_bpe.train(corpus, 500)\n",
        "\n",
        "    # Tempo de execução\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Treinamento em {elapsed_time:.2f} segundos.\")\n",
        "\n",
        "    # Salva para evitar novo treinamento\n",
        "    with open(model_file, 'wb') as file:\n",
        "        pickle.dump(my_bpe, file)\n",
        "    print(\"Modelo salvo em 'my_bpe.pkl'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul01g_x7s5Pl",
        "outputId": "1ed9acf2-b48a-49f6-9aa3-a9c3fc2fed8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[65, 291, 76, 387, 289, 375, 258, 110, 294, 99, 101, 300, 293, 49, 48, 391, 68, 101, 122, 310, 382, 323, 465, 49, 53, 46]\n"
          ]
        }
      ],
      "source": [
        "# Vamos codificar algo\n",
        "test = my_bpe.encode('Ada Lovelace nasceu em 10 de Dezembro de 1815.')\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qryc1gqItr_X",
        "outputId": "7c63886b-6391-4c0b-fdca-83f6cb6ea42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ada Lovelace nasceu em 10 de Dezembro de 1815.\n"
          ]
        }
      ],
      "source": [
        "# Vamos descodificar algo\n",
        "print(my_bpe.decode(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIKdJefbt0tF",
        "outputId": "bd93962b-c1fe-404d-cdb4-0c3823570fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary 257 with tokens (32, 261) decodes to \" de \"\n",
            "Vocabulary 258 with tokens (32, 328) decodes to \" || \"\n",
            "Vocabulary 259 with tokens (41, 32) decodes to \") \"\n",
            "Vocabulary 260 with tokens (41, 260) decodes to \"), \"\n",
            "Vocabulary 261 with tokens (42, 32) decodes to \"* \"\n",
            "Vocabulary 262 with tokens (44, 32) decodes to \", \"\n",
            "Vocabulary 263 with tokens (45, 32) decodes to \"- \"\n",
            "Vocabulary 264 with tokens (45, 341) decodes to \"-se \"\n",
            "Vocabulary 265 with tokens (46, 32) decodes to \". \"\n",
            "Vocabulary 266 with tokens (48, 32) decodes to \"0 \"\n",
            "Vocabulary 267 with tokens (49, 32) decodes to \"1 \"\n",
            "Vocabulary 268 with tokens (49, 56) decodes to \"18\"\n",
            "Vocabulary 269 with tokens (49, 57) decodes to \"19\"\n",
            "Vocabulary 270 with tokens (50, 32) decodes to \"2 \"\n",
            "Vocabulary 271 with tokens (50, 48) decodes to \"20\"\n",
            "Vocabulary 272 with tokens (51, 32) decodes to \"3 \"\n",
            "Vocabulary 273 with tokens (52, 32) decodes to \"4 \"\n",
            "Vocabulary 274 with tokens (53, 32) decodes to \"5 \"\n",
            "Vocabulary 275 with tokens (58, 32) decodes to \": \"\n",
            "Vocabulary 276 with tokens (59, 32) decodes to \"; \"\n",
            "Vocabulary 277 with tokens (61, 32) decodes to \"= \"\n",
            "Vocabulary 278 with tokens (61, 61) decodes to \"==\"\n",
            "Vocabulary 279 with tokens (65, 32) decodes to \"A \"\n",
            "Vocabulary 280 with tokens (67, 286) decodes to \"Cat\"\n",
            "Vocabulary 281 with tokens (79, 32) decodes to \"O \"\n",
            "Vocabulary 282 with tokens (97, 32) decodes to \"a \"\n",
            "Vocabulary 283 with tokens (97, 98) decodes to \"ab\"\n",
            "Vocabulary 284 with tokens (97, 99) decodes to \"ac\"\n",
            "Vocabulary 285 with tokens (97, 100) decodes to \"ad\"\n",
            "Vocabulary 286 with tokens (97, 103) decodes to \"ag\"\n",
            "Vocabulary 287 with tokens (97, 105) decodes to \"ai\"\n",
            "Vocabulary 288 with tokens (97, 108) decodes to \"al\"\n",
            "Vocabulary 289 with tokens (97, 109) decodes to \"am\"\n",
            "Vocabulary 290 with tokens (97, 110) decodes to \"an\"\n",
            "Vocabulary 291 with tokens (97, 112) decodes to \"ap\"\n",
            "Vocabulary 292 with tokens (97, 114) decodes to \"ar\"\n",
            "Vocabulary 293 with tokens (97, 115) decodes to \"as\"\n",
            "Vocabulary 294 with tokens (97, 116) decodes to \"at\"\n",
            "Vocabulary 295 with tokens (97, 118) decodes to \"av\"\n",
            "Vocabulary 296 with tokens (97, 256) decodes to \"ao \"\n",
            "Vocabulary 297 with tokens (97, 259) decodes to \"as \"\n",
            "Vocabulary 298 with tokens (97, 260) decodes to \"a, \"\n",
            "Vocabulary 299 with tokens (97, 261) decodes to \"ade \"\n",
            "Vocabulary 300 with tokens (97, 263) decodes to \"am \"\n",
            "Vocabulary 301 with tokens (97, 270) decodes to \"a. \"\n",
            "Vocabulary 302 with tokens (97, 271) decodes to \"ado \"\n",
            "Vocabulary 303 with tokens (97, 280) decodes to \"aç\"\n",
            "Vocabulary 304 with tokens (98, 108) decodes to \"bl\"\n",
            "Vocabulary 305 with tokens (98, 114) decodes to \"br\"\n",
            "Vocabulary 306 with tokens (99, 104) decodes to \"ch\"\n",
            "Vocabulary 307 with tokens (99, 105) decodes to \"ci\"\n",
            "Vocabulary 308 with tokens (99, 108) decodes to \"cl\"\n",
            "Vocabulary 309 with tokens (99, 111) decodes to \"co\"\n",
            "Vocabulary 310 with tokens (99, 314) decodes to \"cul\"\n",
            "Vocabulary 311 with tokens (100, 101) decodes to \"de\"\n",
            "Vocabulary 312 with tokens (100, 105) decodes to \"di\"\n",
            "Vocabulary 313 with tokens (100, 117) decodes to \"du\"\n",
            "Vocabulary 314 with tokens (100, 256) decodes to \"do \"\n",
            "Vocabulary 315 with tokens (100, 257) decodes to \"da \"\n",
            "Vocabulary 316 with tokens (100, 258) decodes to \"de \"\n",
            "Vocabulary 317 with tokens (100, 268) decodes to \"des\"\n",
            "Vocabulary 318 with tokens (100, 272) decodes to \"dos \"\n",
            "Vocabulary 319 with tokens (100, 275) decodes to \"das \"\n",
            "Vocabulary 320 with tokens (101, 32) decodes to \"e \"\n",
            "Vocabulary 321 with tokens (101, 99) decodes to \"ec\"\n",
            "Vocabulary 322 with tokens (101, 100) decodes to \"ed\"\n",
            "Vocabulary 323 with tokens (101, 103) decodes to \"eg\"\n",
            "Vocabulary 324 with tokens (101, 105) decodes to \"ei\"\n",
            "Vocabulary 325 with tokens (101, 108) decodes to \"el\"\n",
            "Vocabulary 326 with tokens (101, 109) decodes to \"em\"\n",
            "Vocabulary 327 with tokens (101, 110) decodes to \"en\"\n",
            "Vocabulary 328 with tokens (101, 114) decodes to \"er\"\n",
            "Vocabulary 329 with tokens (101, 115) decodes to \"es\"\n",
            "Vocabulary 330 with tokens (101, 116) decodes to \"et\"\n",
            "Vocabulary 331 with tokens (101, 118) decodes to \"ev\"\n",
            "Vocabulary 332 with tokens (101, 120) decodes to \"ex\"\n",
            "Vocabulary 333 with tokens (101, 259) decodes to \"es \"\n",
            "Vocabulary 334 with tokens (101, 260) decodes to \"e, \"\n",
            "Vocabulary 335 with tokens (101, 263) decodes to \"em \"\n",
            "Vocabulary 336 with tokens (102, 111) decodes to \"fo\"\n",
            "Vocabulary 337 with tokens (102, 264) decodes to \"for\"\n",
            "Vocabulary 338 with tokens (103, 117) decodes to \"gu\"\n",
            "Vocabulary 339 with tokens (105, 32) decodes to \"i \"\n",
            "Vocabulary 340 with tokens (105, 97) decodes to \"ia\"\n",
            "Vocabulary 341 with tokens (105, 99) decodes to \"ic\"\n",
            "Vocabulary 342 with tokens (105, 100) decodes to \"id\"\n",
            "Vocabulary 343 with tokens (105, 103) decodes to \"ig\"\n",
            "Vocabulary 344 with tokens (105, 108) decodes to \"il\"\n",
            "Vocabulary 345 with tokens (105, 109) decodes to \"im\"\n",
            "Vocabulary 346 with tokens (105, 110) decodes to \"in\"\n",
            "Vocabulary 347 with tokens (105, 114) decodes to \"ir\"\n",
            "Vocabulary 348 with tokens (105, 115) decodes to \"is\"\n",
            "Vocabulary 349 with tokens (105, 116) decodes to \"it\"\n",
            "Vocabulary 350 with tokens (105, 118) decodes to \"iv\"\n",
            "Vocabulary 351 with tokens (105, 122) decodes to \"iz\"\n",
            "Vocabulary 352 with tokens (105, 256) decodes to \"io \"\n",
            "Vocabulary 353 with tokens (105, 257) decodes to \"ia \"\n",
            "Vocabulary 354 with tokens (105, 259) decodes to \"is \"\n",
            "Vocabulary 355 with tokens (105, 269) decodes to \"ico\"\n",
            "Vocabulary 356 with tokens (105, 282) decodes to \"ici\"\n",
            "Vocabulary 357 with tokens (105, 285) decodes to \"ist\"\n",
            "Vocabulary 358 with tokens (109, 32) decodes to \"m \"\n",
            "Vocabulary 359 with tokens (109, 357) decodes to \"mais \"\n",
            "Vocabulary 360 with tokens (110, 256) decodes to \"no \"\n",
            "Vocabulary 361 with tokens (110, 257) decodes to \"na \"\n",
            "Vocabulary 362 with tokens (110, 282) decodes to \"nci\"\n",
            "Vocabulary 363 with tokens (111, 32) decodes to \"o \"\n",
            "Vocabulary 364 with tokens (111, 99) decodes to \"oc\"\n",
            "Vocabulary 365 with tokens (111, 103) decodes to \"og\"\n",
            "Vocabulary 366 with tokens (111, 108) decodes to \"ol\"\n",
            "Vocabulary 367 with tokens (111, 109) decodes to \"om\"\n",
            "Vocabulary 368 with tokens (111, 110) decodes to \"on\"\n",
            "Vocabulary 369 with tokens (111, 114) decodes to \"or\"\n",
            "Vocabulary 370 with tokens (111, 115) decodes to \"os\"\n",
            "Vocabulary 371 with tokens (111, 116) decodes to \"ot\"\n",
            "Vocabulary 372 with tokens (111, 118) decodes to \"ov\"\n",
            "Vocabulary 373 with tokens (111, 259) decodes to \"os \"\n",
            "Vocabulary 374 with tokens (111, 260) decodes to \"o, \"\n",
            "Vocabulary 375 with tokens (111, 270) decodes to \"o. \"\n",
            "Vocabulary 376 with tokens (111, 300) decodes to \"ou \"\n",
            "Vocabulary 377 with tokens (111, 335) decodes to \"out\"\n",
            "Vocabulary 378 with tokens (112, 101) decodes to \"pe\"\n",
            "Vocabulary 379 with tokens (112, 108) decodes to \"pl\"\n",
            "Vocabulary 380 with tokens (112, 111) decodes to \"po\"\n",
            "Vocabulary 381 with tokens (112, 114) decodes to \"pr\"\n",
            "Vocabulary 382 with tokens (112, 265) decodes to \"per\"\n",
            "Vocabulary 383 with tokens (112, 267) decodes to \"par\"\n",
            "Vocabulary 384 with tokens (112, 281) decodes to \"pri\"\n",
            "Vocabulary 385 with tokens (112, 289) decodes to \"pel\"\n",
            "Vocabulary 386 with tokens (112, 298) decodes to \"pro\"\n",
            "Vocabulary 387 with tokens (112, 318) decodes to \"por \"\n",
            "Vocabulary 388 with tokens (112, 368) decodes to \"pres\"\n",
            "Vocabulary 389 with tokens (112, 370) decodes to \"port\"\n",
            "Vocabulary 390 with tokens (113, 117) decodes to \"qu\"\n",
            "Vocabulary 391 with tokens (114, 97) decodes to \"ra\"\n",
            "Vocabulary 392 with tokens (114, 101) decodes to \"re\"\n",
            "Vocabulary 393 with tokens (114, 105) decodes to \"ri\"\n",
            "Vocabulary 394 with tokens (114, 111) decodes to \"ro\"\n",
            "Vocabulary 395 with tokens (114, 117) decodes to \"ru\"\n",
            "Vocabulary 396 with tokens (114, 256) decodes to \"ro \"\n",
            "Vocabulary 397 with tokens (114, 258) decodes to \"re \"\n",
            "Vocabulary 398 with tokens (114, 266) decodes to \"ran\"\n",
            "Vocabulary 399 with tokens (114, 268) decodes to \"res\"\n",
            "Vocabulary 400 with tokens (115, 32) decodes to \"s \"\n",
            "Vocabulary 401 with tokens (115, 101) decodes to \"se\"\n",
            "Vocabulary 402 with tokens (115, 111) decodes to \"so\"\n",
            "Vocabulary 403 with tokens (115, 116) decodes to \"st\"\n",
            "Vocabulary 404 with tokens (115, 117) decodes to \"su\"\n",
            "Vocabulary 405 with tokens (115, 258) decodes to \"se \"\n",
            "Vocabulary 406 with tokens (115, 260) decodes to \"s, \"\n",
            "Vocabulary 407 with tokens (115, 279) decodes to \"são \"\n",
            "Vocabulary 408 with tokens (116, 256) decodes to \"to \"\n",
            "Vocabulary 409 with tokens (116, 265) decodes to \"ter\"\n",
            "Vocabulary 410 with tokens (117, 32) decodes to \"u \"\n",
            "Vocabulary 411 with tokens (117, 108) decodes to \"ul\"\n",
            "Vocabulary 412 with tokens (117, 109) decodes to \"um\"\n",
            "Vocabulary 413 with tokens (117, 110) decodes to \"un\"\n",
            "Vocabulary 414 with tokens (117, 114) decodes to \"ur\"\n",
            "Vocabulary 415 with tokens (117, 115) decodes to \"us\"\n",
            "Vocabulary 416 with tokens (117, 116) decodes to \"ut\"\n",
            "Vocabulary 417 with tokens (117, 263) decodes to \"um \"\n",
            "Vocabulary 418 with tokens (118, 105) decodes to \"vi\"\n",
            "Vocabulary 419 with tokens (121, 32) decodes to \"y \"\n",
            "Vocabulary 420 with tokens (122, 32) decodes to \"z \"\n",
            "Vocabulary 421 with tokens (124, 32) decodes to \"| \"\n",
            "Vocabulary 422 with tokens (124, 301) decodes to \"|| \"\n",
            "Vocabulary 423 with tokens (195, 160) decodes to \"à\"\n",
            "Vocabulary 424 with tokens (195, 161) decodes to \"á\"\n",
            "Vocabulary 425 with tokens (195, 162) decodes to \"â\"\n",
            "Vocabulary 426 with tokens (195, 163) decodes to \"ã\"\n",
            "Vocabulary 427 with tokens (195, 167) decodes to \"ç\"\n",
            "Vocabulary 428 with tokens (195, 169) decodes to \"é\"\n",
            "Vocabulary 429 with tokens (195, 170) decodes to \"ê\"\n",
            "Vocabulary 430 with tokens (195, 173) decodes to \"í\"\n",
            "Vocabulary 431 with tokens (195, 179) decodes to \"ó\"\n",
            "Vocabulary 432 with tokens (195, 181) decodes to \"õ\"\n",
            "Vocabulary 433 with tokens (195, 186) decodes to \"ú\"\n",
            "Vocabulary 434 with tokens (226, 128) decodes to \"�\"\n",
            "Vocabulary 435 with tokens (256, 261) decodes to \"o de \"\n",
            "Vocabulary 436 with tokens (257, 109) decodes to \"a m\"\n",
            "Vocabulary 437 with tokens (257, 258) decodes to \"a e \"\n",
            "Vocabulary 438 with tokens (257, 261) decodes to \"a de \"\n",
            "Vocabulary 439 with tokens (257, 271) decodes to \"a do \"\n",
            "Vocabulary 440 with tokens (262, 116) decodes to \"ent\"\n",
            "Vocabulary 441 with tokens (264, 32) decodes to \"or \"\n",
            "Vocabulary 442 with tokens (264, 116) decodes to \"ort\"\n",
            "Vocabulary 443 with tokens (265, 32) decodes to \"er \"\n",
            "Vocabulary 444 with tokens (266, 100) decodes to \"and\"\n",
            "Vocabulary 445 with tokens (266, 116) decodes to \"ant\"\n",
            "Vocabulary 446 with tokens (266, 271) decodes to \"ando \"\n",
            "Vocabulary 447 with tokens (267, 32) decodes to \"ar \"\n",
            "Vocabulary 448 with tokens (268, 115) decodes to \"ess\"\n",
            "Vocabulary 449 with tokens (268, 116) decodes to \"est\"\n",
            "Vocabulary 450 with tokens (268, 260) decodes to \"es, \"\n",
            "Vocabulary 451 with tokens (269, 108) decodes to \"col\"\n",
            "Vocabulary 452 with tokens (269, 109) decodes to \"com\"\n",
            "Vocabulary 453 with tokens (269, 110) decodes to \"con\"\n",
            "Vocabulary 454 with tokens (269, 263) decodes to \"com \"\n",
            "Vocabulary 455 with tokens (270, 65) decodes to \". A\"\n",
            "Vocabulary 456 with tokens (270, 69) decodes to \". E\"\n",
            "Vocabulary 457 with tokens (272, 261) decodes to \"os de \"\n",
            "Vocabulary 458 with tokens (273, 104) decodes to \"inh\"\n",
            "Vocabulary 459 with tokens (274, 32) decodes to \"al \"\n",
            "Vocabulary 460 with tokens (275, 261) decodes to \"as de \"\n",
            "Vocabulary 461 with tokens (276, 256) decodes to \"ão \"\n",
            "Vocabulary 462 with tokens (277, 257) decodes to \"ada \"\n",
            "Vocabulary 463 with tokens (277, 272) decodes to \"ados \"\n",
            "Vocabulary 464 with tokens (278, 256) decodes to \"ento \"\n",
            "Vocabulary 465 with tokens (278, 258) decodes to \"ente \"\n",
            "Vocabulary 466 with tokens (280, 279) decodes to \"ção \"\n",
            "Vocabulary 467 with tokens (282, 288) decodes to \"cion\"\n",
            "Vocabulary 468 with tokens (283, 103) decodes to \"reg\"\n",
            "Vocabulary 469 with tokens (284, 258) decodes to \"que \"\n",
            "Vocabulary 470 with tokens (287, 32) decodes to \"é \"\n",
            "Vocabulary 471 with tokens (287, 263) decodes to \"ém \"\n",
            "Vocabulary 472 with tokens (288, 116) decodes to \"ont\"\n",
            "Vocabulary 473 with tokens (292, 257) decodes to \"ica \"\n",
            "Vocabulary 474 with tokens (294, 115) decodes to \"ass\"\n",
            "Vocabulary 475 with tokens (294, 260) decodes to \"as, \"\n",
            "Vocabulary 476 with tokens (296, 98) decodes to \"amb\"\n",
            "Vocabulary 477 with tokens (299, 32) decodes to \"á \"\n",
            "Vocabulary 478 with tokens (299, 281) decodes to \"ári\"\n",
            "Vocabulary 479 with tokens (302, 32) decodes to \"== \"\n",
            "Vocabulary 480 with tokens (302, 361) decodes to \"=== \"\n",
            "Vocabulary 481 with tokens (304, 259) decodes to \"ais \"\n",
            "Vocabulary 482 with tokens (305, 114) decodes to \"eir\"\n",
            "Vocabulary 483 with tokens (306, 279) decodes to \"ação \"\n",
            "Vocabulary 484 with tokens (307, 395) decodes to \"idade \"\n",
            "Vocabulary 485 with tokens (309, 260) decodes to \"os, \"\n",
            "Vocabulary 486 with tokens (315, 116) decodes to \"cont\"\n",
            "Vocabulary 487 with tokens (316, 57) decodes to \"199\"\n",
            "Vocabulary 488 with tokens (317, 116) decodes to \"part\"\n",
            "Vocabulary 489 with tokens (317, 257) decodes to \"para \"\n",
            "Vocabulary 490 with tokens (319, 257) decodes to \"uma \"\n",
            "Vocabulary 491 with tokens (329, 281) decodes to \"óri\"\n",
            "Vocabulary 492 with tokens (330, 256) decodes to \"como \"\n",
            "Vocabulary 493 with tokens (334, 48) decodes to \"200\"\n",
            "Vocabulary 494 with tokens (334, 49) decodes to \"201\"\n",
            "Vocabulary 495 with tokens (365, 417) decodes to \"ênci\"\n",
            "Vocabulary 496 with tokens (371, 290) decodes to \"ões \"\n",
            "Vocabulary 497 with tokens (380, 148) decodes to \"—\"\n",
            "Vocabulary 498 with tokens (383, 32) decodes to \". A \"\n",
            "Vocabulary 499 with tokens (400, 354) decodes to \"foi \"\n",
            "Vocabulary 500 with tokens (401, 109) decodes to \"form\"\n"
          ]
        }
      ],
      "source": [
        "# Vamos imprimir as subpalavras\n",
        "my_bpe.print_subwords()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
